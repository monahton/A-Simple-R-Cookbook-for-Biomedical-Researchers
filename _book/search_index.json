[["index.html", "A Simple R Cookbook for Biomedical Researchers Preface", " A Simple R Cookbook for Biomedical Researchers Monah Abou Alezz 2026-01-14 Preface Welcome to A Simple R Cookbook for Biomedical Researchers. This book is written for wet lab scientists, clinicians, and other biomedical researchers who want to analyse their own data in R without becoming full-time programmers. We will focus on data analysis workflows rather than deep computer science. You will learn enough R to be dangerous in the good sense: able to clean, explore, visualise, and model your data, while understanding what you are doing and why. Throughout the book: We assume you have basic familiarity with experimental design and statistics (e.g. p-values, means, standard deviation), but we explain concepts when we use them. We avoid jargon as much as possible and define it when we cannot. We show complete examples that you can copy, paste, and adapt to your own projects. The examples are inspired by typical biomedical datasets: gene expression, clinical measurements, and simple experimental readouts. We will use a small, simulated biomedical dataset packaged in an R package called biomedrdata that you can install and load. What you will learn: How to work comfortably in R and RStudio. The main data types and data structures in R that appear all the time in analysis scripts. How to import, clean, and wrangle biomedical data into analysis-ready form. How to join multiple tables (for example, clinical data + assay data). How to visualise your data to check quality and communicate results. How to apply these skills to a realistic biomedical dataset. What you will not learn in depth: General-purpose software engineering, advanced programming paradigms, or how to build complex R packages from scratch. The full mathematical theory behind all statistical methods. Those topics are important, but not necessary for you to become effective at analysing your own data. If you can run PCRs, Western blots, or cell culture experiments, you can absolutely learn to use R. We will go step by step, with many examples and explanations. Occasionally, we might even make a light joke to keep things human, but we will keep the overall tone professional and focused. Let us begin. "],["introduction-r-for-bioinformatics-and-biomedical-data-analysis.html", "Chapter 1 Introduction: R for Bioinformatics and Biomedical Data Analysis", " Chapter 1 Introduction: R for Bioinformatics and Biomedical Data Analysis R is a free, open-source language designed for data analysis and statistics. It has become a standard tool in many areas of science, including bioinformatics, genomics, and clinical research. In this chapter we will: Explain what R is and why it is useful for biomedical researchers. Discuss how R is used in bioinformatics. Clarify the goals and style of this book. "],["what-is-r.html", "1.1 What is R?", " 1.1 What is R? R is both: A programming language, and An environment for data analysis. You can think of R as a very smart calculator that understands tables of data, can draw figures, and can run statistical tests. Unlike spreadsheet software, R keeps a record of exactly what you did in code, which makes your work reproducible and transparent. 1.1.1 Why use R instead of only spreadsheets or GUI tools? Many biomedical researchers start with tools like Excel, GraphPad Prism, or instrument vendor software. These tools are useful, but they have limitations: Repeating the same analysis for many datasets becomes tedious. Manual steps are easy to forget or mis-click, which can lead to subtle errors. Collaboration is harder because others cannot easily see every step you took. R addresses these issues because: Your analysis is written as code, so it can be saved, shared, and re-run. You can apply the same code to new data with minimal changes. You have access to thousands of packages contributed by other scientists. "],["r-in-bioinformatics-and-biomedical-research.html", "1.2 R in bioinformatics and biomedical research", " 1.2 R in bioinformatics and biomedical research R is widely used in: Transcriptomics (microarrays, RNA-seq, single-cell RNA-seq) Genomics and variant analysis Proteomics and metabolomics Flow cytometry and imaging data analysis Clinical data analysis and epidemiology The Bioconductor project (a large collection of R packages for bioinformatics) has made R particularly strong for high-throughput data. However, in this book we do not assume you are doing advanced omics analysis from day one. Instead, we focus on the core skills that apply to almost any biomedical dataset: Reading data into R Cleaning and transforming variables Combining multiple tables Summarising and visualising results Once you are comfortable with those foundations, you will be able to pick up more specialised tools (for RNA-seq, proteomics, etc.) much more easily. "],["less-about-programming-more-about-data-analysis.html", "1.3 Less about programming, more about data analysis", " 1.3 Less about programming, more about data analysis There are many excellent books that teach R as a general programming language or focus heavily on computer science concepts. This book takes a different approach. Our priorities are: Clarity: Use simple language and concrete examples from biomedical research. Practicality: Show tasks you actually need in day-to-day data analysis. Reproducibility: Encourage good habits from the start. We will explain enough programming concepts so that you understand what your code is doing, but we will not dive deep into things like object-oriented programming, advanced software design patterns, or building complex applications. If you can: Load your data into R Clean and reshape it Join different tables Make clear plots Run basic analyses and export the results …then this book has achieved its goal. "],["how-to-use-this-book.html", "1.4 How to use this book", " 1.4 How to use this book You can read the chapters in order, or jump directly to topics you need. However, we recommend that beginners at least skim the early chapters about: R and RStudio Data types and data structures Later chapters on data wrangling and visualisation build on those concepts. Throughout the book we will: Use a consistent coding style. Show example code and the corresponding output. Use a simple, simulated biomedical dataset packaged in biomedrdata. If something is confusing, do not worry—this is normal. Take your time, run the code yourself, and try small variations. Learning R is a bit like learning to pipette: at first it feels awkward, but with practice it becomes second nature. "],["getting-started-with-r-and-rstudio.html", "Chapter 2 Getting Started with R and RStudio", " Chapter 2 Getting Started with R and RStudio In this chapter we explain what R and RStudio are, how they relate to each other, and how to set them up for everyday work. "],["r-vs-rstudio-what-is-the-difference.html", "2.1 R vs RStudio: what is the difference?", " 2.1 R vs RStudio: what is the difference? R is the engine. It is the language and computation engine that reads your code and does the calculations. RStudio is an integrated development environment (IDE) that makes R easier and nicer to use. It provides menus, panes, syntax highlighting, and many shortcuts. You can run R without RStudio (for example, in a plain terminal), but RStudio makes your life much easier, especially when you are starting out. A rough analogy: R is like a powerful microscope. RStudio is like the comfortable lab bench, chair, and light that make using the microscope pleasant and efficient. "],["installing-r.html", "2.2 Installing R", " 2.2 Installing R Go to the Comprehensive R Archive Network (CRAN) website. Download the installer for your operating system (Windows, macOS, or Linux). Run the installer and follow the default options. After installation, you will have an application called R (sometimes “R x.y.z” where x.y.z is the version number). "],["installing-rstudio.html", "2.3 Installing RStudio", " 2.3 Installing RStudio Go to the RStudio (Posit) website and download RStudio Desktop (the free version is fine). Install it as you would any other application. When you open RStudio, it automatically finds your R installation. "],["the-rstudio-layout.html", "2.4 The RStudio layout", " 2.4 The RStudio layout When you open RStudio, you usually see four main panes: Source pane (top-left): where you write and edit scripts (.R files) and notebooks (.Rmd files). Console pane (bottom-left): where R actually runs your code and shows results. Environment / History pane (top-right): shows the objects currently in memory and a history of commands. Files / Plots / Packages / Help / Viewer pane (bottom-right): shows files, plots, installed packages, help pages, etc. You can resize these panes or change their layout in the RStudio options, but the default layout works well for most people. "],["the-r-console.html", "2.5 The R console", " 2.5 The R console The console is where R reads and runs your commands. The prompt usually looks like this: &gt; (Do not type the &gt; yourself; R prints it to indicate it is ready for input.) You can type simple commands into the console and press Enter, for example: 1 + 1 R will respond with: [1] 2 The [1] just means “this is the first element of the result”. For now, you can ignore it. The console is useful for quick experiments, but for real work we strongly recommend using scripts. "],["scripts-and-reproducible-analysis.html", "2.6 Scripts and reproducible analysis", " 2.6 Scripts and reproducible analysis An R script is a plain text file with extension .R that contains sequences of R commands. Advantages of using scripts: You can save your work, run it again later, or share it with collaborators. You can run the entire analysis from top to bottom with a single command. It is easier to debug and to keep track of changes. To create a new script in RStudio: Click File → New File → R Script. A new tab opens in the Source pane. Type some R code, for example: x &lt;- 1:10 mean(x) To run a line, place the cursor on that line and press Cmd+Enter (macOS) or Ctrl+Enter (Windows/Linux). The code runs in the console and the result appears below. We will use scripts extensively in later chapters. "],["projects-in-rstudio.html", "2.7 Projects in RStudio", " 2.7 Projects in RStudio RStudio projects help you organise your files, data, and scripts for each analysis or paper. When you create a project, RStudio: Sets the working directory to the project folder. Remembers your open files and settings. Helps keep separate analyses from interfering with each other. To create a project for this book: In RStudio, click File → New Project…. Choose Existing Directory. Browse to the folder A-Simple-R-Cookbook-for-Biomedical-Researchers. Click Create Project. Now, whenever you open the .Rproj file in that folder, RStudio will load the project with the book. "],["installing-and-loading-packages.html", "2.8 Installing and loading packages", " 2.8 Installing and loading packages R has a small set of functions built in, but most of the power comes from packages. A package is a collection of functions, data, and documentation. To install a package from CRAN, use install.packages() (you only need to do this once per computer): install.packages(&quot;tidyverse&quot;) To use the package in a session, you need to load it with library() every time you start R: library(tidyverse) If R says that a package is not installed, double-check the spelling and your internet connection. "],["summary.html", "2.9 Summary", " 2.9 Summary In this chapter you learned: The difference between R (the language/engine) and RStudio (the user interface). How to install both. How to use the console, scripts, and projects. How to install and load packages. In the next chapters we will explore what kinds of data R works with and how these are represented in memory. "],["working-in-rstudio-your-data-analysis-lab-bench.html", "Chapter 3 Working in RStudio: Your Data Analysis Lab Bench", " Chapter 3 Working in RStudio: Your Data Analysis Lab Bench Now that you know what R and RStudio are, let us look at how to use RStudio effectively for day-to-day data analysis. "],["creating-and-saving-scripts.html", "3.1 Creating and saving scripts", " 3.1 Creating and saving scripts Scripts are where your analyses live. Get into the habit of always working from a script, not only from the console. To create a new script: File → New File → R Script. Save it immediately: File → Save (or Cmd+S / Ctrl+S). Choose a meaningful name, for example 01_import_data.R or qc_experiment1.R. Using numbered prefixes (01, 02, 03, …) keeps related scripts ordered. "],["running-code-from-a-script.html", "3.2 Running code from a script", " 3.2 Running code from a script In the script editor: Run current line: place cursor on a line and press Cmd+Enter / Ctrl+Enter. Run selection: select several lines and press the same shortcut. Run all: select all (Cmd+A / Ctrl+A) and then run. As you run code: Output appears in the console. Objects you create (data frames, vectors, models) appear in the Environment pane. If a command fails, R usually prints an informative error message in red. Do not panic—read it slowly. Often it tells you exactly what went wrong (for example, a misspelled column name). "],["working-directory-and-files.html", "3.3 Working directory and files", " 3.3 Working directory and files The working directory is the folder that R uses as its reference point when reading or writing files. You can see the current working directory with: getwd() In a project, the working directory should be the project folder. This is one of the main reasons we use projects. Instead of using full paths like: &quot;C:/Users/You/Desktop/Experiment1/data.csv&quot; you can use relative paths from the project root, for example: &quot;data/experiment1.csv&quot; This makes your code more portable and easier to share. "],["the-environment-pane.html", "3.4 The Environment pane", " 3.4 The Environment pane The Environment pane (top-right by default) lists the objects currently in memory: Vectors, data frames, lists, models, etc. You can click on a data frame to view it in a spreadsheet-like viewer. This is very handy for quickly checking that your data imported correctly. However, try not to rely too heavily on the mouse. It is good to learn code-based checks, for example: head(my_data) str(my_data) summary(my_data) These commands also show up in your script, making your checks reproducible. "],["plots-and-help-panes.html", "3.5 Plots and Help panes", " 3.5 Plots and Help panes The Plots tab shows figures produced by R. You can: Navigate between previous plots. Export plots to files (PNG, PDF) using the Export button. The Help tab displays documentation. To open help for a function, use: ?mean help(&quot;mean&quot;) or type the function name in the search bar of the Help pane. Documentation can be dense, but scrolling to the Examples section is often helpful. "],["commenting-your-code.html", "3.6 Commenting your code", " 3.6 Commenting your code Comments are text in your script that R ignores. They start with #. Use comments to: Explain what a block of code is doing. Mark sections of your analysis. Leave notes to your future self. Example: # Import clinical data and basic QC clinical &lt;- read.csv(&quot;data/clinical.csv&quot;) # Check for missing values in key variables summary(clinical$age) summary(clinical$outcome) Well-commented code is easier to understand and debug. Remember: your most important collaborator is future you. "],["good-habits-from-the-start.html", "3.7 Good habits from the start", " 3.7 Good habits from the start A few small habits make your life much easier: Save your script frequently. Run your script from the top regularly to ensure everything still works. Keep raw data read-only and perform cleaning steps in code. Use meaningful, consistent object names (for example patients, rna_counts, qc_results). In later chapters we will apply these habits to specific tasks such as data import, cleaning, and visualisation. "],["basic-data-types-in-r.html", "Chapter 4 Basic Data Types in R", " Chapter 4 Basic Data Types in R To work effectively in R, you need to understand the basic data types. These are the kinds of values R can store. In biomedical data analysis you will most often encounter: Numeric values (e.g. concentrations, counts, ages) Character strings (e.g. sample IDs, gene symbols) Logical values (TRUE/FALSE) Factors (categorical variables, e.g. treatment group) Dates and times (e.g. collection dates) We will look at each in turn, with simple examples. "],["numeric-values.html", "4.1 Numeric values", " 4.1 Numeric values Numeric values represent numbers. In R, most numbers you create are of type numeric. Examples: 3.14 42 -0.01 You can assign numbers to objects using &lt;-: age &lt;- 35 concentration &lt;- 2.5 You can perform arithmetic: age + 5 # 40 concentration * 2 # 5 R can also represent very large or very small numbers using scientific notation, e.g. 1e6 for one million. "],["character-strings.html", "4.2 Character strings", " 4.2 Character strings Character strings are pieces of text, surrounded by quotes \"\" or ''. Examples: sample_id &lt;- &quot;S1&quot; gene &lt;- &quot;TP53&quot; cell_line &lt;- &quot;HeLa&quot; Character strings are used for: IDs Gene names Free-text labels You can combine strings with paste() or paste0(): paste(&quot;Patient&quot;, 1:3) # &quot;Patient 1&quot; &quot;Patient 2&quot; &quot;Patient 3&quot; "],["logical-values-truefalse.html", "4.3 Logical values (TRUE/FALSE)", " 4.3 Logical values (TRUE/FALSE) Logical values represent truth: TRUE or FALSE. They are extremely important in data analysis because they allow you to filter and subset data. Examples: passed_qc &lt;- TRUE is_treated &lt;- c(TRUE, FALSE, TRUE) Logical values often come from comparisons: age &lt;- c(30, 45, 60) age &gt; 40 # FALSE TRUE TRUE You can use logical vectors to select rows from a data frame, as we will see later. "],["factors-categorical-variables.html", "4.4 Factors (categorical variables)", " 4.4 Factors (categorical variables) A factor is R’s way of representing categorical data: variables that take on a limited number of levels, such as: Treatment group: control, drugA, drugB Sex: male, female (or better yet, a more inclusive coding in modern datasets) Stage: I, II, III, IV You can create a factor with factor(): group &lt;- factor(c(&quot;control&quot;, &quot;drug&quot;, &quot;control&quot;, &quot;drug&quot;)) Factors remember the set of allowed values (levels). This is useful for: Plotting (consistent order of groups) Modelling (treating groups correctly in regression) You can check the levels with: levels(group) If you convert character variables to factors too early, they can be slightly annoying to work with. A common modern approach is to keep categorical variables as characters until you need factors for modelling or plotting. "],["dates-and-times.html", "4.5 Dates and times", " 4.5 Dates and times Dates and times are extremely common in clinical and experimental data. R has special classes for dates (Date) and date-times (POSIXct / POSIXlt). You can create a date with as.Date(): visit_date &lt;- as.Date(&quot;2024-03-01&quot;) Internally, dates are stored as the number of days since 1970-01-01, but you usually do not need to worry about that. For more complex date-time handling (time zones, intervals, etc.), the lubridate package is very helpful. "],["missing-values-na.html", "4.6 Missing values: NA", " 4.6 Missing values: NA Real-world data is messy. Subjects drop out, experiments fail, values are not recorded. In R, missing values are represented as NA. Example: age &lt;- c(34, NA, 52) Important: many functions treat NA specially. For instance: mean(age) # NA mean(age, na.rm = TRUE) # 43 The argument na.rm = TRUE tells R to ignore missing values when computing the mean. You can test for missingness with is.na(): is.na(age) # FALSE TRUE FALSE Handling missing data correctly is crucial in biomedical research. We will revisit this topic in data cleaning and wrangling chapters. "],["inspecting-data-types.html", "4.7 Inspecting data types", " 4.7 Inspecting data types To check the type of an object, you can use: class(x) – the high-level class typeof(x) – the low-level internal type (often less important for beginners) Example: x &lt;- 1:5 class(x) # &quot;integer&quot; name &lt;- &quot;Alice&quot; class(name) # &quot;character&quot; In data frames, different columns can have different types. Always check that the types make sense after importing data. In the next chapter we will see how these basic types are combined into larger data structures such as vectors, matrices, and data frames. "],["data-structures-in-r.html", "Chapter 5 Data Structures in R", " Chapter 5 Data Structures in R Data types (numeric, character, etc.) are the building blocks. Data structures are how R organises multiple values together. The most important data structures for data analysis are: Vectors Matrices Lists Data frames and tibbles "],["vectors.html", "5.1 Vectors", " 5.1 Vectors A vector is a one-dimensional sequence of values of the same basic type. Examples: ages &lt;- c(34, 27, 45) sample_ids &lt;- c(&quot;S1&quot;, &quot;S2&quot;, &quot;S3&quot;) is_treated &lt;- c(TRUE, FALSE, TRUE) You can access elements with square brackets: ages[1] # 34 ages[2:3] # 27 and 45 Many functions in R are vectorised: they operate on entire vectors at once. ages + 1 # 35 28 46 "],["matrices.html", "5.2 Matrices", " 5.2 Matrices A matrix is a two-dimensional structure (rows and columns) where all elements have the same type (usually numeric). Matrices are common in high-throughput assays, e.g. gene expression counts (genes × samples). Example: m &lt;- matrix(1:6, nrow = 2, ncol = 3) You can index a matrix with two indices: m[row, column]. However, in modern R data analysis we often prefer data frames or tibbles for most tasks, because they handle mixed types better (for example, numeric measurements and character sample IDs in the same object). "],["lists.html", "5.3 Lists", " 5.3 Lists A list can contain elements of different types and structures. Example: patient &lt;- list( id = &quot;P001&quot;, age = 54, biomarkers = c(IL6 = 2.3, CRP = 5.1), notes = &quot;Baseline sample before treatment&quot; ) Lists are very flexible and are used to store complex results: Model fits Results from bioinformatics pipelines Nested experimental structures You can access elements with $ or by index: patient$age patient[[&quot;biomarkers&quot;]] As a wet lab biologist, you will mainly interact with lists when working with outputs from packages; you rarely need to construct very complex lists yourself. "],["data-frames.html", "5.4 Data frames", " 5.4 Data frames A data frame is the workhorse of data analysis in R. It represents tabular data (like a spreadsheet) where: Each column is a vector of the same length. Columns can have different types (numeric, character, factor, etc.). Each row usually represents one observation (e.g. one patient, one sample). You can create a simple data frame with data.frame(): clinical &lt;- data.frame( patient_id = c(&quot;P001&quot;, &quot;P002&quot;, &quot;P003&quot;), age = c(54, 60, 47), treatment = c(&quot;control&quot;, &quot;drug&quot;, &quot;drug&quot;), stringsAsFactors = FALSE ) (Setting stringsAsFactors = FALSE avoids automatic conversion of characters to factors in older versions of R.) You can access columns with $: clinical$age You can also access rows and columns with [row, column] notation: clinical[1, ] # first row clinical[, 2] # second column We will use data frames throughout the book for clinical data, assay results, and derived summaries. "],["tibbles-modern-data-frames.html", "5.5 Tibbles (modern data frames)", " 5.5 Tibbles (modern data frames) The tibble is a modern reimagining of the data frame provided by the tibble / tidyverse packages. Tibbles: Print more nicely (showing only the first rows and columns). Do not convert strings to factors automatically. Are generally safer and more predictable. You can create a tibble with tibble::tibble(): library(tibble) clinical_tbl &lt;- tibble( patient_id = c(&quot;P001&quot;, &quot;P002&quot;, &quot;P003&quot;), age = c(54, 60, 47), treatment = c(&quot;control&quot;, &quot;drug&quot;, &quot;drug&quot;) ) In this book we will often use tibbles, but the concepts apply equally to base R data frames. "],["inspecting-data-frames-and-tibbles.html", "5.6 Inspecting data frames and tibbles", " 5.6 Inspecting data frames and tibbles Useful functions to inspect data frames and tibbles include: head(x) – first few rows dim(x) – number of rows and columns names(x) – column names str(x) – structure and types Examples: head(clinical_tbl) str(clinical_tbl) These give you a quick overview of what you are working with. In the next chapters, we will learn how to import, clean, and transform these data structures for analysis. "],["importing-processing-and-cleaning-data.html", "Chapter 6 Importing, Processing, and Cleaning Data", " Chapter 6 Importing, Processing, and Cleaning Data Most real-world biomedical data starts life as: CSV files exported from instruments or LIMS Excel spreadsheets Text files Before you can analyse the data, you need to import it into R and often clean it. In this chapter we will: Import data from CSV files. Take a first look at the data. Fix common problems (column types, missing values, inconsistent labels). We will use functions from base R and the readr / tidyverse packages. "],["importing-csv-files.html", "6.1 Importing CSV files", " 6.1 Importing CSV files CSV (comma-separated values) files are a common, simple format for tabular data. Using base R: clinical &lt;- read.csv(&quot;data/clinical.csv&quot;, stringsAsFactors = FALSE) Using readr (recommended for larger files): library(readr) clinical &lt;- read_csv(&quot;data/clinical.csv&quot;) read_csv() prints a summary of the columns and their guessed types, which is very helpful for checking that R understood your data correctly. "],["first-look-at-the-data.html", "6.2 First look at the data", " 6.2 First look at the data Right after importing, inspect the data: head(clinical) str(clinical) summary(clinical) Questions to ask yourself: Do the column names make sense? Are numeric columns really numeric (not accidentally read as character)? Are categorical columns (like treatment group) encoded consistently? How many missing values do you see? If something looks wrong, it is usually easier to fix it early. "],["renaming-columns.html", "6.3 Renaming columns", " 6.3 Renaming columns Sometimes column names are long or contain spaces or odd characters. You can rename columns in several ways. With dplyr::rename(): library(dplyr) clinical &lt;- clinical %&gt;% rename( patient_id = PATIENT_ID, treatment = TreatmentGroup, age = AgeYears ) This creates shorter, more consistent names. "],["converting-column-types.html", "6.4 Converting column types", " 6.4 Converting column types If a column was imported with the wrong type, you can convert it. Examples: # Convert character to numeric clinical$age &lt;- as.numeric(clinical$age) # Convert numeric codes to factor with labels clinical$stage &lt;- factor(clinical$stage_code, levels = c(1, 2, 3, 4), labels = c(&quot;I&quot;, &quot;II&quot;, &quot;III&quot;, &quot;IV&quot;)) # Convert date strings to Date clinical$visit_date &lt;- as.Date(clinical$visit_date) Always re-check with str() after conversions. "],["handling-missing-values.html", "6.5 Handling missing values", " 6.5 Handling missing values Missing values (NA) are inevitable. Important steps: Identify which variables have missing values. Decide whether to drop rows, impute values, or keep them explicit. To count missing values per column: colSums(is.na(clinical)) To remove rows with missing values in a particular column: clinical_complete &lt;- clinical %&gt;% filter(!is.na(age)) The appropriate strategy depends on your study design and analysis goals. The main point here is to be aware of missing data and handle it deliberately, not by accident. "],["creating-new-variables.html", "6.6 Creating new variables", " 6.6 Creating new variables Often you need to create derived variables, such as BMI, response status, or log-transformed measurements. With dplyr::mutate(): clinical &lt;- clinical %&gt;% mutate( bmi = weight_kg / (height_m^2), responder = if_else(delta_biomarker &lt; -0.5, &quot;responder&quot;, &quot;non-responder&quot;) ) Creating clear, well-named variables makes your later analysis and plotting much easier. "],["filtering-and-selecting-columns.html", "6.7 Filtering and selecting columns", " 6.7 Filtering and selecting columns Two very common cleaning operations are: Filtering rows (keeping a subset of patients or samples). Selecting columns (keeping only the variables you need). Examples with dplyr: # Keep only treated patients clinical_treated &lt;- clinical %&gt;% filter(treatment == &quot;drug&quot;) # Keep only key columns clinical_small &lt;- clinical %&gt;% select(patient_id, age, treatment, outcome) We will cover these verbs in more depth in the chapter on data wrangling. "],["saving-cleaned-data.html", "6.8 Saving cleaned data", " 6.8 Saving cleaned data Once you have cleaned your data, it is often helpful to save a cleaned version for later use. write_csv(clinical, &quot;data/clinical_clean.csv&quot;) or as an R-specific binary file (smaller and faster to load): saveRDS(clinical, file = &quot;data/clinical_clean.rds&quot;) You can later load it with: clinical &lt;- readRDS(&quot;data/clinical_clean.rds&quot;) In the next chapter we will systematically learn the main data wrangling verbs that make these kinds of operations easier and more consistent. "],["data-wrangling-with-dplyr.html", "Chapter 7 Data Wrangling with dplyr", " Chapter 7 Data Wrangling with dplyr “Data wrangling” means transforming raw data into a clean, analysis-ready form. The dplyr package (part of the tidyverse) provides a consistent set of verbs for common operations: filter() – keep rows select() – keep columns mutate() – add or transform columns arrange() – sort rows summarise() – compute summary statistics group_by() – define groups of rows for grouped operations We will introduce each with simple biomedical-flavoured examples. First, load the package: library(dplyr) Assume we have a clinical data frame with columns: patient_id age sex treatment outcome biomarker_baseline biomarker_followup "],["filter-keep-rows.html", "7.1 filter(): keep rows", " 7.1 filter(): keep rows filter() keeps rows that meet certain conditions. Example: keep only treated patients older than 50. clinical_treated50 &lt;- clinical %&gt;% filter(treatment == &quot;drug&quot;, age &gt; 50) You can use logical operators: == equal to != not equal to &gt; greater than &lt; less than &gt;=, &lt;= &amp; and | or "],["select-keep-or-reorder-columns.html", "7.2 select(): keep or reorder columns", " 7.2 select(): keep or reorder columns select() chooses a subset of columns. clinical_small &lt;- clinical %&gt;% select(patient_id, age, treatment, outcome) You can also rename columns while selecting: clinical_renamed &lt;- clinical %&gt;% select(id = patient_id, tx = treatment, everything()) "],["mutate-add-or-transform-columns.html", "7.3 mutate(): add or transform columns", " 7.3 mutate(): add or transform columns mutate() creates new columns or modifies existing ones. Example: compute change in biomarker and percentage change. clinical &lt;- clinical %&gt;% mutate( delta_biomarker = biomarker_followup - biomarker_baseline, pct_change = 100 * delta_biomarker / biomarker_baseline ) You can create logical flags: clinical &lt;- clinical %&gt;% mutate( responder = pct_change &lt;= -50 ) "],["arrange-sort-rows.html", "7.4 arrange(): sort rows", " 7.4 arrange(): sort rows arrange() orders rows by one or more columns. clinical_sorted &lt;- clinical %&gt;% arrange(desc(pct_change)) This sorts patients by percentage change, from largest to smallest. "],["group_by-and-summarise-grouped-summaries.html", "7.5 group_by() and summarise(): grouped summaries", " 7.5 group_by() and summarise(): grouped summaries One of the most powerful patterns is grouped summarisation. Example: mean biomarker change by treatment group. summary_by_treatment &lt;- clinical %&gt;% group_by(treatment) %&gt;% summarise( n = n(), mean_delta = mean(delta_biomarker, na.rm = TRUE), sd_delta = sd(delta_biomarker, na.rm = TRUE) ) Here: group_by(treatment) tells dplyr to form groups of rows by treatment. summarise() computes one row per group. You can group by multiple variables, e.g. group_by(treatment, sex). "],["the-pipe.html", "7.6 The pipe %&gt;%", " 7.6 The pipe %&gt;% You may have noticed the %&gt;% symbol (the pipe). x %&gt;% f() is a readable way of writing f(x). It passes the object on the left as the first argument to the function on the right. Instead of nesting function calls like this: summarise(group_by(clinical, treatment), mean_delta = mean(delta_biomarker)) we can write: clinical %&gt;% group_by(treatment) %&gt;% summarise(mean_delta = mean(delta_biomarker)) This flows from top to bottom, making complex transformations much easier to read. (Modern R also has a base pipe |&gt;; both are acceptable. This book uses %&gt;% because it is common in the tidyverse.) "],["putting-it-together-a-typical-cleaning-pipeline.html", "7.7 Putting it together: a typical cleaning pipeline", " 7.7 Putting it together: a typical cleaning pipeline Here is an example pipeline that: Filters to treated patients. Creates derived variables. Keeps only key columns. Summarises by outcome. clinical_summary &lt;- clinical %&gt;% filter(treatment == &quot;drug&quot;) %&gt;% mutate( delta_biomarker = biomarker_followup - biomarker_baseline, responder = delta_biomarker &lt;= -0.5 ) %&gt;% select(patient_id, age, sex, responder, delta_biomarker) %&gt;% group_by(responder) %&gt;% summarise( n = n(), mean_age = mean(age, na.rm = TRUE), mean_delta = mean(delta_biomarker, na.rm = TRUE) ) As you read and write such pipelines, imagine each step as a small lab protocol step: filter samples, annotate, measure, summarise. In the next chapter we will see how to join multiple data frames (for example, clinical information and assay results) using similar ideas. "],["joining-data-frames.html", "Chapter 8 Joining Data Frames", " Chapter 8 Joining Data Frames In biomedical research, data often comes from multiple sources: Clinical data collected at the bedside Laboratory assay results Genomic or proteomic measurements To analyse these together, you need to join tables on a common key (e.g. patient ID, sample ID). The dplyr package provides a family of join functions: left_join() inner_join() right_join() full_join() semi_join() and anti_join() We will focus on the most common ones and use simple examples. Assume we have: clinical – one row per patient assay – one row per sample (linked to patient by patient_id) "],["left_join-keep-all-rows-from-the-left-table.html", "8.1 left_join(): keep all rows from the left table", " 8.1 left_join(): keep all rows from the left table left_join(x, y, by = \"key\") joins two tables, keeping all rows from x and adding matching columns from y. Example: library(dplyr) combined &lt;- clinical %&gt;% left_join(assay, by = &quot;patient_id&quot;) If a patient is in clinical but has no assay data, the new columns from assay will be NA for that patient. left_join() is often the safest default in biomedical work, where you typically have a master clinical table and optional extra information. "],["inner_join-keep-only-matches.html", "8.2 inner_join(): keep only matches", " 8.2 inner_join(): keep only matches inner_join() keeps only rows with matches in both tables. overlap &lt;- clinical %&gt;% inner_join(assay, by = &quot;patient_id&quot;) Patients who are missing from either clinical or assay are dropped. This is useful when you want to restrict analysis to subjects with complete data in both sources. "],["full_join-keep-everything.html", "8.3 full_join(): keep everything", " 8.3 full_join(): keep everything full_join() keeps all rows from both tables, filling missing values with NA where necessary. full &lt;- clinical %&gt;% full_join(assay, by = &quot;patient_id&quot;) This can be helpful for data auditing (checking which patients appear where), but is less common for final analyses. "],["specifying-multiple-keys.html", "8.4 Specifying multiple keys", " 8.4 Specifying multiple keys Sometimes you need to join by more than one variable, for example patient_id and visit. combined &lt;- clinical_long %&gt;% left_join(biomarkers_long, by = c(&quot;patient_id&quot;, &quot;visit&quot;)) This ensures that you match the right visit for each patient. "],["checking-join-results.html", "8.5 Checking join results", " 8.5 Checking join results After a join, always check: Number of rows: did it increase, decrease, or stay the same? Number of missing values in key columns Whether there were duplicate keys dplyr will warn you if there are many-to-many matches (both tables have duplicates of the key). This is often a sign that you should double-check your assumptions. Example checks: nrow(clinical) nrow(assay) nrow(combined) colSums(is.na(combined)) Joining tables correctly is crucial; a wrong join can silently produce incorrect analyses. In later chapters, we will use joins to combine the clinical and biomarker data from our example dataset. "],["data-visualisation-with-ggplot2.html", "Chapter 9 Data Visualisation with ggplot2", " Chapter 9 Data Visualisation with ggplot2 Visualisation is essential for: Exploring data quality Detecting patterns and outliers Communicating results The ggplot2 package (part of the tidyverse) is a powerful and flexible system for making plots in R. In this chapter we cover: Basic grammar of graphics Scatter plots Boxplots and violin plots Bar plots Faceting (small multiples) "],["basics-of-ggplot2.html", "9.1 Basics of ggplot2", " 9.1 Basics of ggplot2 First, load the package: library(ggplot2) The basic idea is: ggplot(data, aes(x = ..., y = ..., color = ...)) + geom_...( ) Where: data is a data frame or tibble. aes() defines aesthetics: how variables map to visual properties. geom_... chooses the type of plot (points, lines, bars, etc.). "],["scatter-plots.html", "9.2 Scatter plots", " 9.2 Scatter plots Scatter plots are useful for examining relationships between two continuous variables, e.g. baseline vs follow-up biomarker. ggplot(clinical, aes(x = biomarker_baseline, y = biomarker_followup)) + geom_point() You can colour points by a categorical variable: ggplot(clinical, aes(x = biomarker_baseline, y = biomarker_followup, color = treatment)) + geom_point() Add a diagonal reference line: ggplot(clinical, aes(x = biomarker_baseline, y = biomarker_followup)) + geom_point() + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;red&quot;) "],["boxplots.html", "9.3 Boxplots", " 9.3 Boxplots Boxplots summarise the distribution of a continuous variable across groups. Example: biomarker change by treatment. ggplot(clinical, aes(x = treatment, y = delta_biomarker)) + geom_boxplot() You can overlay individual points (often with a small random jitter): ggplot(clinical, aes(x = treatment, y = delta_biomarker)) + geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.1, alpha = 0.5) "],["bar-plots.html", "9.4 Bar plots", " 9.4 Bar plots Bar plots are useful for counts or proportions. Example: number of patients by treatment group. ggplot(clinical, aes(x = treatment)) + geom_bar() By default, geom_bar() counts rows in each group. You can also summarise yourself and plot pre-computed counts. "],["faceting-small-multiples.html", "9.5 Faceting: small multiples", " 9.5 Faceting: small multiples Faceting creates multiple panels for different levels of a variable. Example: scatter plots of baseline vs follow-up biomarker, separated by treatment. ggplot(clinical, aes(x = biomarker_baseline, y = biomarker_followup)) + geom_point() + facet_wrap(~ treatment) This helps compare patterns across subgroups. "],["labels-and-themes.html", "9.6 Labels and themes", " 9.6 Labels and themes Always label your axes and legends clearly. ggplot(clinical, aes(x = biomarker_baseline, y = biomarker_followup, color = treatment)) + geom_point() + labs( x = &quot;Baseline biomarker (ng/mL)&quot;, y = &quot;Follow-up biomarker (ng/mL)&quot;, color = &quot;Treatment group&quot;, title = &quot;Change in biomarker by treatment&quot; ) You can adjust the overall look with themes, e.g.: p + theme_minimal() or p + theme_bw() Where p is a plot object created earlier. "],["saving-plots.html", "9.7 Saving plots", " 9.7 Saving plots To save a plot to a file, use ggsave(). p &lt;- ggplot(clinical, aes(x = treatment, y = delta_biomarker)) + geom_boxplot() ggsave(&quot;figures/biomarker_boxplot.png&quot;, plot = p, width = 6, height = 4, dpi = 300) Figures saved this way can be included in manuscripts, presentations, or reports. In the final chapter we will use these ideas to analyse a small simulated biomedical dataset end-to-end. "],["case-study-analysing-a-biomedical-biomarker-dataset.html", "Chapter 10 Case Study: Analysing a Biomedical Biomarker Dataset", " Chapter 10 Case Study: Analysing a Biomedical Biomarker Dataset In this chapter we bring everything together using a small simulated clinical biomarker dataset from the biomedrdata package. The dataset, clinical_biomarkers, contains: One row per patient. Baseline and follow-up biomarker measurements. Treatment assignment. Basic clinical variables (age, sex, outcome). Our goals: Import and inspect the data. Clean and transform variables. Summarise and visualise biomarker changes by treatment group. "],["loading-the-dataset.html", "10.1 Loading the dataset", " 10.1 Loading the dataset First, install and load the package once you have built it: # install.packages(&quot;devtools&quot;) # if needed # devtools::install(&quot;../biomedrdata&quot;) library(biomedrdata) data(&quot;clinical_biomarkers&quot;) clinical &lt;- clinical_biomarkers Take a first look: head(clinical) str(clinical) summary(clinical) "],["cleaning-and-derived-variables.html", "10.2 Cleaning and derived variables", " 10.2 Cleaning and derived variables We create a change score for the biomarker and a simple responder flag. library(dplyr) clinical &lt;- clinical %&gt;% mutate( delta_biomarker = biomarker_followup - biomarker_baseline, pct_change = 100 * delta_biomarker / biomarker_baseline, responder = pct_change &lt;= -50 ) Check the distribution of changes: summary(clinical$delta_biomarker) summary(clinical$pct_change) "],["summaries-by-treatment.html", "10.3 Summaries by treatment", " 10.3 Summaries by treatment Compute summaries by treatment group: summary_by_tx &lt;- clinical %&gt;% group_by(treatment) %&gt;% summarise( n = n(), mean_age = mean(age, na.rm = TRUE), mean_baseline = mean(biomarker_baseline, na.rm = TRUE), mean_followup = mean(biomarker_followup, na.rm = TRUE), mean_delta = mean(delta_biomarker, na.rm = TRUE), responders = sum(responder, na.rm = TRUE), responder_rate = responders / n ) summary_by_tx Interpretation questions you might ask: Does the treatment group show a larger average decrease in biomarker? What proportion of patients in each group are responders? "],["visualising-biomarker-change.html", "10.4 Visualising biomarker change", " 10.4 Visualising biomarker change Use boxplots to compare delta_biomarker across treatments. library(ggplot2) ggplot(clinical, aes(x = treatment, y = delta_biomarker)) + geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.1, alpha = 0.4) + labs( x = &quot;Treatment group&quot;, y = &quot;Change in biomarker (follow-up - baseline)&quot;, title = &quot;Biomarker change by treatment&quot; ) + theme_minimal() You can also look at percentage change: ggplot(clinical, aes(x = treatment, y = pct_change)) + geom_boxplot(outlier.shape = NA) + geom_jitter(width = 0.1, alpha = 0.4) + labs( x = &quot;Treatment group&quot;, y = &quot;Percentage change in biomarker&quot;, title = &quot;Percentage change by treatment&quot; ) + theme_minimal() "],["visualising-responder-rates.html", "10.5 Visualising responder rates", " 10.5 Visualising responder rates Create a simple bar plot of responder rates: responder_summary &lt;- clinical %&gt;% group_by(treatment) %&gt;% summarise(responder_rate = mean(responder, na.rm = TRUE)) responder_summary ggplot(responder_summary, aes(x = treatment, y = responder_rate)) + geom_col() + scale_y_continuous(labels = scales::percent_format()) + labs( x = &quot;Treatment group&quot;, y = &quot;Responder rate&quot;, title = &quot;Responder rates by treatment&quot; ) + theme_minimal() "],["next-steps.html", "10.6 Next steps", " 10.6 Next steps This case study illustrated a basic but realistic workflow: Load a biomedical dataset. Inspect and clean the data. Create derived variables. Summarise results by group. Visualise distributions and key outcomes. You can adapt this pattern to your own datasets by: Changing variable names. Adjusting filters and derived variables. Choosing plots that match your endpoints. As you become more comfortable, you can extend this with statistical modelling, more complex experimental designs, and domain-specific methods (e.g. survival analysis, mixed models, omics pipelines), many of which are available as R packages. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
